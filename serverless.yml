service: testability-workshop

provider:
  name: aws
  runtime: python3.7
  stage: dev
  region: ap-northeast-1
  environment:
    STAGE: ${self:provider.stage}
    TABLE_NAME: ${self:service}-ec2_resource_table-${self:provider.stage}
    ACTION_STREAM: ${self:service}-SomethingActionStream-${self:provider.stage}
  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "s3:ListBucket"
      Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
    - Effect: "Allow"
      Action:
        - "kinesis:*"
      Resource: "*"        
    - Effect: "Allow"
      Action:
        - "dynamodb:PutItem"
        - "dynamodb:BatchWrite*"
        - "dynamodb:BatchGet*"
        - "dynamodb:Get*"
        - "dynamodb:Query"
        - "dynamodb:Scan"
        - "dynamodb:Update*"
      Resource:
        - Fn::Join:
          - ""
          - - "arn:aws:dynamodb:*:*:table/"
            - ${self:provider.environment.TABLE_NAME}
        - Fn::Join:
          - ""
          - - "arn:aws:dynamodb:*:*:table/"
            - ${self:provider.environment.TABLE_NAME}
            - "/*"

# you can define service wide environment variables here
#  environment:
#    variable1: value1

plugins:
  - serverless-dotenv-plugin
  - serverless-python-requirements

# you can add packaging information here
#package:
#  include:
#    - include-me.py
#    - include-me-dir/**
#  exclude:
#    - exclude-me.py
#    - exclude-me-dir/**

functions:
  Ec2Collector:
    handler: ec2collector/functions/collector.collect
    events:
      - schedule: cron(0 17 * * ? *)
  SomethingAction:
    handler: ec2collector/functions/collector.something_action
    events:
      - schedule: cron(0 18 * * ? *)
  DoSomething:
    handler: ec2collector/functions/action.do_something
    event:
      - stream:
          type: kinesis
          batchSize: 1
          startingPosition: LATEST
          arn:
            Fn::GetAtt: [ SomethingStream , Arn ]
#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - http:
#          path: users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp
#      - alb:
#          listenerArn: arn:aws:elasticloadbalancing:us-east-1:XXXXXX:listener/app/my-load-balancer/50dc6c495c0c9188/
#          priority: 1
#          conditions:
#            host: example.com
#            path: /hello

#    Define function environment variables here
#    environment:
#      variable2: value2

resources:
  Resources:
    EC2ResourceTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:provider.environment.TABLE_NAME}
        AttributeDefinitions:
          - AttributeName: InstanceId
            AttributeType: S
        KeySchema:
          - AttributeName: InstanceId
            KeyType: HASH
        BillingMode: PAY_PER_REQUEST
    SomethingStream:
      Type: AWS::Kinesis::Stream
      Properties:
        Name: ${self:provider.environment.ACTION_STREAM}
        ShardCount: 1
  Outputs:
    EC2ResourceTable:
      Description: Table ARN
      Value: 
        Fn::GetAtt: [ EC2ResourceTable, Arn ]
